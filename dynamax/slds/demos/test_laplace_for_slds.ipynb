{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Laplace approximation on a simulated SLDS model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from dynamax.slds.models import SLDS\n",
    "from dynamax.slds.test_models import simulate_slds\n",
    "from dynamax.slds.laplace import laplace_approximation, block_tridiag_mvn_sample\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from dynamax.utils.plotting import plot_states_and_timeseries\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "MVN = tfd.MultivariateNormalFullCovariance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switching linear dynamical systems (SLDS) in JAX\n",
    "\n",
    "An SLDS is a state space model with discrete latent states $z_t \\in [K]$, continuous states $x_t \\in \\mathbb{R}^D$, and observations $y_t \\in \\mathbb{R}^N$. The model is,\n",
    "\n",
    "\\begin{align}\n",
    "p(z_{1:T}, x_{1:T}, y_{1:T}; \\theta)\n",
    "&= \\prod_{t=1}^T \\mathrm{Cat}(z_t \\mid \\pi_{z_{t-1}}) \\, \\mathrm{N}(x_t \\mid A_{z_t} x_{t-1} + b_{z_t}, Q_{z_t}) \\, \\mathrm{N}(y_t \\mid C x_t + d, R)\n",
    "\\end{align}\n",
    "\n",
    "with parameters $\\theta = \\{\\{\\pi_k, A_k, b_k, Q_k\\}_{k=1}^K, C, d, R\\}$. (We're ignoring the intial distribution, but that also has some parameters.)\n",
    "\n",
    "_Note: we're assuming the emission parameters are shared by all discrete states, but we could relax that._\n",
    "\n",
    "\n",
    "First, let's try to sample from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random number generator\n",
    "key = jr.PRNGKey(0)\n",
    "\n",
    "# simulate data from a toy SLDS model\n",
    "zs, xs, ys, slds, params = simulate_slds(key)\n",
    "\n",
    "# create distributions that are passed to the laplace approximation\n",
    "P = params.transition_matrix\n",
    "As = params.dynamics_matrices\n",
    "bs = params.dynamics_biases\n",
    "Qs = params.dynamics_covs\n",
    "C = params.emission_matrix\n",
    "d = params.emission_bias\n",
    "R = params.emission_cov\n",
    "\n",
    "latent_dim = slds.latent_dim\n",
    "emission_dim = slds.emission_dim\n",
    "num_states = slds.num_states"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define log prob functions that close over zs and params\n",
    "log_prob = lambda xs, ys: slds.log_prob(ys, zs, xs, params)\n",
    "initial_distribution = lambda x0: MVN(jnp.zeros(latent_dim), jnp.eye(latent_dim)).log_prob(x0)\n",
    "dynamics_distribution = lambda t, xt, xtp1: MVN(As[zs[t+1]] @ xt + bs[zs[t+1]], Qs[zs[t+1]]).log_prob(xtp1)\n",
    "emission_distribution = lambda t, xt, yt: MVN(C @ xt + d, R).log_prob(yt)\n",
    "\n",
    "# run the laplace approximation\n",
    "log_normalizer, Ex, ExxT, ExxnT, J_diag, J_lower_diag, h = \\\n",
    "laplace_approximation(log_prob, \n",
    "                    initial_distribution,\n",
    "                    dynamics_distribution, \n",
    "                    emission_distribution, \n",
    "                    jnp.zeros_like(xs), \n",
    "                    ys, \n",
    "                    method=\"L-BFGS\", \n",
    "                    num_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the approximate posterior\n",
    "x_sample = block_tridiag_mvn_sample(jr.PRNGKey(0), J_diag, J_lower_diag, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "fig, ax = plot_states_and_timeseries(zs, xs)\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_title(\"latent states\")\n",
    "plt.show()\n",
    "\n",
    "cov_x = ExxT - jnp.einsum('ti,tj->tij', Ex, Ex)\n",
    "fig, ax = plot_states_and_timeseries(zs, Ex, jnp.sqrt(vmap(jnp.diag)(cov_x)))\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_title(\"inferred latent states\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plot_states_and_timeseries(zs, x_sample)\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_title(\"inferred latent states\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now fit with Laplace EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_params = copy.deepcopy(params)\n",
    "test_slds = SLDS(num_states, latent_dim, emission_dim, params)\n",
    "lps, fit_zs, fit_xs, fit_params = test_slds._fit_laplace_em(ys, zs, xs, \n",
    "                                                            initialize_params, \n",
    "                                                            num_iters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize log probs\n",
    "plt.plot(lps)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"log prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize inferred states\n",
    "fig, ax = plot_states_and_timeseries(fit_zs, fit_xs)\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_title(\"fitted latent states\")\n",
    "\n",
    "fig, ax = plot_states_and_timeseries(zs, xs)\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_title(\"true latent states\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f001baa031417ffc7012e27246ef797abdde390e17fc75b247c486dc5c62d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
